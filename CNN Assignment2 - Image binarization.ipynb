{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Generate training set\n",
    "batch_size = 1280\n",
    "gt_all = os.listdir('gt')\n",
    "\n",
    "batch_train_x = np.zeros((batch_size,64,64,3))\n",
    "batch_train_y = np.zeros((batch_size,64,64,3))\n",
    "for a in range(batch_size):\n",
    "    i = random.randint(0,len(gt_all)-1)\n",
    "\n",
    "    name = gt_all[i]\n",
    "    name = name.replace('_segmentation','')\n",
    "    name = name.replace('png','jpg')\n",
    "    img = cv2.imread(os.path.join('gt',gt_all[i]))\n",
    "    img = cv2.resize(img,(64,64))\n",
    "    batch_train_y[a] = img\n",
    "    if name in os.listdir('melanoma'):\n",
    "        img = cv2.imread(os.path.join('melanoma',name))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(64,64))\n",
    "            batch_train_x[a] = img\n",
    "    else:\n",
    "        img = cv2.imread(os.path.join('others',name))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(64,64))\n",
    "            batch_train_x[a] = img\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Generate test set\n",
    "batch_size_test = 200\n",
    "batch_test_x = np.zeros((batch_size_test,64,64,3))\n",
    "batch_test_y = np.zeros((batch_size_test,64,64,3))\n",
    "for a in range(batch_size_test):\n",
    "    i = random.randint(0,len(gt_all)-1)\n",
    "\n",
    "    name = gt_all[i]\n",
    "    name = name.replace('_segmentation','')\n",
    "    name = name.replace('png','jpg')\n",
    "    img = cv2.imread(os.path.join('gt',gt_all[i]))\n",
    "    img = cv2.resize(img,(64,64))\n",
    "    batch_test_y[a] = img\n",
    "    if name in os.listdir('melanoma'):\n",
    "        img = cv2.imread(os.path.join('melanoma',name))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(64,64))\n",
    "            batch_test_x[a] = img\n",
    "    else:\n",
    "        img = cv2.imread(os.path.join('others',name))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(64,64))\n",
    "            batch_test_x[a] = img\n",
    "            \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Generate Validation set\n",
    "batch_size_val = 320\n",
    "batch_val_x = np.zeros((batch_size_val,64,64,3))\n",
    "batch_val_y = np.zeros((batch_size_val,64,64,3))\n",
    "for a in range(batch_size_val):\n",
    "    i = random.randint(0,len(gt_all)-1)\n",
    "\n",
    "    name = gt_all[i]\n",
    "    name = name.replace('_segmentation','')\n",
    "    name = name.replace('png','jpg')\n",
    "    img = cv2.imread(os.path.join('gt',gt_all[i]))\n",
    "    img = cv2.resize(img,(64,64))\n",
    "    batch_val_y[a] = img\n",
    "    if name in os.listdir('melanoma'):\n",
    "        img = cv2.imread(os.path.join('melanoma',name))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(64,64))\n",
    "            batch_val_x[a] = img\n",
    "    else:\n",
    "        img = cv2.imread(os.path.join('others',name))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(64,64))\n",
    "            batch_val_x[a] = img\n",
    "            \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with 4 layers of convolution (32 filters), Maxpool (2,2), 4 layers of convolution (64 filters), Maxpool(2,2), 5 layers of convolution (32 filters), Upsampling to image size, one layer fo convolution (3 filters)\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),padding='same',\n",
    "                 activation='relu',input_shape = (64,64,3)))\n",
    "model2.add(Conv2D(32, (3,3),padding='same',activation='tanh'))\n",
    "model2.add(Conv2D(32, (3,3),padding='same',activation='tanh'))\n",
    "model2.add(Conv2D(32, (3,3),padding='same',activation='tanh'))\n",
    "\n",
    "model2.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))\n",
    "model2.add(Conv2D(64, (3,3),padding='same',activation='tanh'))\n",
    "model2.add(Conv2D(64, (3,3),padding='same',activation='tanh'))\n",
    "model2.add(Conv2D(64, (3,3),padding='same',activation='tanh'))\n",
    "model2.add(Conv2D(64, (3,3),padding='same',activation='tanh'))\n",
    "\n",
    "model2.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))\n",
    "model2.add(Conv2D(32, (3,3),padding='same',activation='tanh'))\n",
    "model2.add(Conv2D(32, (3,3),padding='same',activation='tanh'))\n",
    "model2.add(Conv2D(32, (3,3),padding='same',activation='tanh'))\n",
    "model2.add(Conv2D(32, (3,3),padding='same',activation='tanh'))\n",
    "model2.add(Conv2D(32, (3,3),padding='same',activation='tanh'))\n",
    "\n",
    "model2.add(UpSampling2D(size = (4,4)))\n",
    "model2.add(Conv2D(32, (3,3),padding='same',activation='tanh'))\n",
    "model2.add(Conv2D(32, (3,3),padding='same',activation='tanh'))\n",
    "model2.add(Conv2D(3, (3,3),padding='same',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=losses.binary_crossentropy,\n",
    "              optimizer=optimizers.SGD(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/10\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 742.1203 - acc: 0.7897 - val_loss: 828.9099 - val_acc: 0.7972\n",
      "Epoch 2/10\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 787.6469 - acc: 0.8071 - val_loss: 828.9099 - val_acc: 0.7972\n",
      "Epoch 3/10\n",
      "1280/1280 [==============================] - 230s 179ms/step - loss: 787.6469 - acc: 0.8071 - val_loss: 828.9099 - val_acc: 0.7972\n",
      "Epoch 4/10\n",
      "1280/1280 [==============================] - 215s 168ms/step - loss: 787.6469 - acc: 0.8071 - val_loss: 828.9099 - val_acc: 0.7972\n",
      "Epoch 5/10\n",
      "1280/1280 [==============================] - 218s 171ms/step - loss: 787.6469 - acc: 0.8071 - val_loss: 828.9099 - val_acc: 0.7972\n",
      "Epoch 6/10\n",
      "1280/1280 [==============================] - 202s 158ms/step - loss: 787.6469 - acc: 0.8071 - val_loss: 828.9099 - val_acc: 0.7972\n",
      "Epoch 7/10\n",
      "1280/1280 [==============================] - 202s 158ms/step - loss: 787.6469 - acc: 0.8071 - val_loss: 828.9099 - val_acc: 0.7972\n",
      "Epoch 8/10\n",
      "1280/1280 [==============================] - 202s 158ms/step - loss: 787.6469 - acc: 0.8071 - val_loss: 828.9099 - val_acc: 0.7972\n",
      "Epoch 9/10\n",
      "1280/1280 [==============================] - 205s 160ms/step - loss: 787.6469 - acc: 0.8071 - val_loss: 828.9099 - val_acc: 0.7972\n",
      "Epoch 10/10\n",
      "1280/1280 [==============================] - 203s 159ms/step - loss: 787.6469 - acc: 0.8071 - val_loss: 828.9099 - val_acc: 0.7972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x77361b32e8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(batch_train_x,batch_train_y,validation_data=(batch_val_x,batch_val_y),batch_size =50,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 10s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[777.81264160156252, 0.80946044921875004]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(batch_test_x,batch_test_y,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
